{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+yzkf2JcLQpNu+rF9Bxjh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitu2568/NLP_INTENT_CLASSIFICATION/blob/master/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfj2oeoqzBwk",
        "colab_type": "code",
        "outputId": "792ed479-498a-470a-a54e-3a098f3d32e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar 26 17:15:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    24W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGNk5ozozK_F",
        "colab_type": "code",
        "outputId": "7bf78ae0-538f-4f0d-a2c2-cf6539faf591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip install tensorflow-gpu >> /dev/null"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlCNOGbKzlK9",
        "colab_type": "code",
        "outputId": "ae19c0ac-fed0-495f-9fb0-4ca1d53217ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install --upgrade grpcio >> /dev/null"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement grpcio~=1.24.3, but you'll have grpcio 1.27.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mquhAIFAzpf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tqdm  >> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Idg3bwzxdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-for-tf2 >> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBIcSSDF0Bum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sentencepiece >> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C0eCxyK0Dyv",
        "colab_type": "code",
        "outputId": "61df24d3-f312-4cee-8f4e-216b5ff88b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import os\n",
        "import math\n",
        "import datetime\n",
        "import json\n",
        "import requests\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import bert\n",
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzdVkh3p0qFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = json.loads(requests.get('https://raw.githubusercontent.com/clinc/oos-eval/master/data/data_small.json').text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAv52dpN6cQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "''' Getting Training data '''\n",
        "inscope_train = pd.DataFrame(df['train'],columns=['query','intent'])\n",
        "oss_train = pd.DataFrame(df['oos_train'],columns=['query','intent'])\n",
        "\n",
        "''' Getting Validation data '''\n",
        "inscope_val = pd.DataFrame(df['val'],columns=['query','intent'])\n",
        "oss_val = pd.DataFrame(df['oos_val'],columns=['query','intent'])\n",
        "\n",
        "''' Getting Test data '''\n",
        "inscope_test = pd.DataFrame(df['test'],columns=['query','intent'])\n",
        "oss_test = pd.DataFrame(df['oos_test'],columns=['query','intent'])\n",
        "\n",
        "\n",
        "train_df = pd.concat([inscope_train,oss_train])\n",
        "val_df = pd.concat([inscope_val,oss_val])\n",
        "test_df = pd.concat([inscope_test,oss_test])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZpsR8-X6gkQ",
        "colab_type": "code",
        "outputId": "0c4b5fc9-3f58-4c0e-abd3-d804173fbc95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7600, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgT9wGZr6pyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.append(val_df).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcHvo8Re6-hE",
        "colab_type": "code",
        "outputId": "2af1e076-082a-4259-ab9b-a5acb64c2bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10700, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw3D9rDp7Cfp",
        "colab_type": "code",
        "outputId": "192a6d21-1539-43fd-959c-e901c9bf25f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can you walk me through setting up direct depo...</td>\n",
              "      <td>direct_deposit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i want to switch to direct deposit</td>\n",
              "      <td>direct_deposit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>set up direct deposit for me</td>\n",
              "      <td>direct_deposit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how do i go about setting up direct deposit</td>\n",
              "      <td>direct_deposit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i need to get my paycheck direct deposited to ...</td>\n",
              "      <td>direct_deposit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query          intent\n",
              "0  can you walk me through setting up direct depo...  direct_deposit\n",
              "1                 i want to switch to direct deposit  direct_deposit\n",
              "2                       set up direct deposit for me  direct_deposit\n",
              "3        how do i go about setting up direct deposit  direct_deposit\n",
              "4  i need to get my paycheck direct deposited to ...  direct_deposit"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxgw5NJy76k5",
        "colab_type": "code",
        "outputId": "bfbda832-625d-433f-ba14-68d02e932b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        " !wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-26 17:17:09--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.14.112, 2607:f8b0:4007:80e::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.14.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   122MB/s    in 3.2s    \n",
            "\n",
            "2020-03-26 17:17:13 (122 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3uJV8zD99r2",
        "colab_type": "code",
        "outputId": "ff7aa4a7-93e0-4415-f839-627272b19776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc6xwNGi-G-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(\"model\", exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sdw2qcFchxv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUTqASNs-g96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv uncased_L-12_H-768_A-12/ model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NOoF3Is-m1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
        "bert_check_point_dir = os.path.join(\"model/\", bert_model_name)\n",
        "bert_check_point_file = os.path.join(bert_check_point_dir, \"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_check_point_dir, \"bert_config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX4zTxEW-9rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IntentClassificationTask:\n",
        "  DATA_COLUMN = \"query\"\n",
        "  LABEL_COLUMN = \"intent\"\n",
        "\n",
        "  def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_seq_len = 0\n",
        "    self.classes = classes\n",
        "    \n",
        "    ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._split_data, [train, test])\n",
        "\n",
        "    print(\"maximum seq_len\", self.max_seq_len)\n",
        "    self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "    self.train_x, self.test_x = map(self._zeropadding, [self.train_x, self.test_x])\n",
        "\n",
        "  def _split_data(self, df):\n",
        "    x, y = [], []\n",
        "    \n",
        "    for _, row in tqdm(df.iterrows()):\n",
        "      text, label = row[IntentClassificationTask.DATA_COLUMN], row[IntentClassificationTask.LABEL_COLUMN]\n",
        "      # It tokenize the given Sequence\n",
        "      tokens = self.tokenizer.tokenize(text)\n",
        "      # Adding the starter and ending for each sequence\n",
        "      tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "      #Convert the tokens from text to vector format\n",
        "      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "      self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
        "      x.append(token_ids)\n",
        "      # Using the index of labels\n",
        "      y.append(self.classes.index(label))\n",
        "\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "  def _zeropadding(self, ids):\n",
        "    x = []\n",
        "    for input_ids in ids:\n",
        "      input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
        "      input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
        "      x.append(np.array(input_ids))\n",
        "    return np.array(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yiEigQoDSMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_check_point_dir, \"vocab.txt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEc5Mj8XJ4So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(max_seq_len, bert_check_point_file):\n",
        "\n",
        "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
        "    #Reading from the BERT Config File\n",
        "      bc = StockBertConfig.from_json_string(reader.read())\n",
        "      bert_params = map_stock_config_to_params(bc)\n",
        "      bert_params.adapter_size = None\n",
        "      bert = BertModelLayer.from_params(bert_params, name=\"bert-large-uncased\")\n",
        "        \n",
        "  input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
        "  bert_output = bert(input_ids)\n",
        "\n",
        "  print(\"bert shape\", bert_output.shape)\n",
        "\n",
        "  # Output Layer to input BERT Layer\n",
        "  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
        "  # Adding Drop-out Layer\n",
        "  cls_out = keras.layers.Dropout(0.05)(cls_out)\n",
        "  # Adding Dense output Layer to drop-out Layer (using 'tanh' activation function)\n",
        "  logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
        "  # Adding Drop-out Layer\n",
        "  logits = keras.layers.Dropout(0.05)(logits)\n",
        "  # Adding Dense output Layer to drop-out Layer (using 'softmax' activation function)\n",
        "  logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
        "  \n",
        "  model = keras.Model(inputs=input_ids, outputs=logits)\n",
        "  model.build(input_shape=(None, max_seq_len))\n",
        "\n",
        "  load_stock_weights(bert, bert_check_point_file)\n",
        "        \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Y2mriYRSFT",
        "colab_type": "code",
        "outputId": "4e44d52f-726d-4edb-e7f8-63ade51f2ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "classes = train_df.intent.unique().tolist()\n",
        "\n",
        "data = IntentClassificationTask(train_df, test_df, tokenizer, classes, max_seq_len=128)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10700it [00:02, 4001.42it/s]\n",
            "5500it [00:01, 3944.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "maximum seq_len 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_23udocERkQq",
        "colab_type": "code",
        "outputId": "d94246b7-a176-414a-920f-41391e72f2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model = create_model(data.max_seq_len, bert_check_point_file)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method BertModelLayer.call of <bert.model.BertModelLayer object at 0x7f4eab5c3eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_estimator.contrib'\n",
            "WARNING: Entity <bound method BertModelLayer.call of <bert.model.BertModelLayer object at 0x7f4eab5c3eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_estimator.contrib'\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/layer.py:20: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "bert shape (?, 32, 768)\n",
            "Done loading 196 BERT weights from: model/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7f4eab5c3eb8> (prefix:bert-large-uncased). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
            "Unused weights from checkpoint: \n",
            "\tbert/embeddings/token_type_embeddings\n",
            "\tbert/pooler/dense/bias\n",
            "\tbert/pooler/dense/kernel\n",
            "\tcls/predictions/output_bias\n",
            "\tcls/predictions/transform/LayerNorm/beta\n",
            "\tcls/predictions/transform/LayerNorm/gamma\n",
            "\tcls/predictions/transform/dense/bias\n",
            "\tcls/predictions/transform/dense/kernel\n",
            "\tcls/seq_relationship/output_bias\n",
            "\tcls/seq_relationship/output_weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U00cIYAOSBj-",
        "colab_type": "code",
        "outputId": "49132fa9-d204-47b6-cd26-968441795000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.train_x.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10700, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RShL5-T5SMMt",
        "colab_type": "code",
        "outputId": "79251499-7ab1-4a7f-bf33-155ef7c68605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "data.train_x[5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  2054,  2024,  1996,  4084,  2000,  2275,  2039,  3622,\n",
              "       12816,  2000,  2026,  5252,  4070,   102,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sQN-G8qSQaU",
        "colab_type": "code",
        "outputId": "f7471623-e0b1-4c22-c57c-7690ce35eb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "bert-large-uncased (BertMode (None, 32, 768)           108890112 \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 768)               590592    \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 151)               116119    \n",
            "=================================================================\n",
            "Total params: 109,596,823\n",
            "Trainable params: 109,596,823\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB13MfQUS7-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "  optimizer=keras.optimizers.Adam(2e-5),\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlhBH72ATmT6",
        "colab_type": "code",
        "outputId": "f637ad90-3f45-4f48-c245-279cca41e04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "log_dir = \"log/intent_classification/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "history = model.fit(\n",
        "  x=data.train_x, \n",
        "  y=data.train_y,\n",
        "  validation_split=0.1,\n",
        "  batch_size=32,\n",
        "  shuffle=True,\n",
        "  epochs=20,\n",
        "  callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 9630 samples, validate on 1070 samples\n",
            "Epoch 1/20\n",
            "9630/9630 [==============================] - 112s 12ms/sample - loss: 5.0046 - acc: 0.0241 - val_loss: 5.0072 - val_acc: 0.0206\n",
            "Epoch 2/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.7574 - acc: 0.2916 - val_loss: 4.9392 - val_acc: 0.0935\n",
            "Epoch 3/20\n",
            "9630/9630 [==============================] - 105s 11ms/sample - loss: 4.4982 - acc: 0.5533 - val_loss: 4.6896 - val_acc: 0.3664\n",
            "Epoch 4/20\n",
            "9630/9630 [==============================] - 105s 11ms/sample - loss: 4.3357 - acc: 0.7102 - val_loss: 4.5721 - val_acc: 0.4664\n",
            "Epoch 5/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.2498 - acc: 0.7918 - val_loss: 4.4640 - val_acc: 0.5748\n",
            "Epoch 6/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.1876 - acc: 0.8513 - val_loss: 4.3970 - val_acc: 0.6402\n",
            "Epoch 7/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.1453 - acc: 0.8911 - val_loss: 4.3104 - val_acc: 0.7252\n",
            "Epoch 8/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.1226 - acc: 0.9133 - val_loss: 4.2351 - val_acc: 0.8093\n",
            "Epoch 9/20\n",
            "9630/9630 [==============================] - 105s 11ms/sample - loss: 4.0977 - acc: 0.9363 - val_loss: 4.2267 - val_acc: 0.8187\n",
            "Epoch 10/20\n",
            "9630/9630 [==============================] - 105s 11ms/sample - loss: 4.0782 - acc: 0.9539 - val_loss: 4.1981 - val_acc: 0.8449\n",
            "Epoch 11/20\n",
            "9630/9630 [==============================] - 105s 11ms/sample - loss: 4.0696 - acc: 0.9621 - val_loss: 4.1794 - val_acc: 0.8664\n",
            "Epoch 12/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.0663 - acc: 0.9642 - val_loss: 4.1532 - val_acc: 0.8869\n",
            "Epoch 13/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.0581 - acc: 0.9720 - val_loss: 4.1606 - val_acc: 0.8738\n",
            "Epoch 14/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.0557 - acc: 0.9744 - val_loss: 4.1684 - val_acc: 0.8720\n",
            "Epoch 15/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.0532 - acc: 0.9767 - val_loss: 4.1545 - val_acc: 0.8850\n",
            "Epoch 16/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.0540 - acc: 0.9764 - val_loss: 4.1648 - val_acc: 0.8729\n",
            "Epoch 17/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.0504 - acc: 0.9794 - val_loss: 4.1389 - val_acc: 0.8972\n",
            "Epoch 18/20\n",
            "9630/9630 [==============================] - 104s 11ms/sample - loss: 4.0417 - acc: 0.9882 - val_loss: 4.1460 - val_acc: 0.8944\n",
            "Epoch 19/20\n",
            "9630/9630 [==============================] - 105s 11ms/sample - loss: 4.0416 - acc: 0.9883 - val_loss: 4.1300 - val_acc: 0.9075\n",
            "Epoch 20/20\n",
            "9630/9630 [==============================] - 105s 11ms/sample - loss: 4.0371 - acc: 0.9921 - val_loss: 4.1082 - val_acc: 0.9271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G5wHzamUUD9",
        "colab_type": "code",
        "outputId": "8b5ba0aa-74ad-40e9-f991-65aeb975b326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "_, train_accuracy = model.evaluate(data.train_x, data.train_y)\n",
        "_, test_accuracy = model.evaluate(data.test_x, data.test_y)\n",
        "\n",
        "print(\"training accuracy\", train_accuracy)\n",
        "print(\"test accuracy\", test_accuracy)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10700/10700 [==============================] - 40s 4ms/sample - loss: 4.0410 - acc: 0.9885\n",
            "5500/5500 [==============================] - 21s 4ms/sample - loss: 4.1726 - acc: 0.8667\n",
            "training accuracy 0.98850465\n",
            "test accuracy 0.8667273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Df6laRldg1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}