{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USE_Word_EMbeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsESRiGnzm3mslZ2CHPft5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsukamet/NLPProject/blob/master/USE_Word_EMbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX1aFqW8VYMm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "58df1db8-7e13-4f8b-8bdf-a76f3c781a6a"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install \"tensorflow_hub>=0.6.0\"\n",
        "!pip3 install tensorflow_text==1.15"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.28.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.3)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=89170c527cb38fe681564b1678f8f4426aa71c9c122d1a583dccb228a883a60e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Requirement already satisfied: tensorflow_hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.18.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (46.1.3)\n",
            "Collecting tensorflow_text==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/61/9569353ce3efb8ee818d0d2e2f67afbb19e1e3a56eba3a93986e92949003/tensorflow_text-1.15.0-cp36-cp36m-manylinux1_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.18.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.28.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.2.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZPnhn5keEJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "589be9d8-0503-4e2f-a48d-f10b6c75f149"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import keras\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rQ9KgYxVhlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "embed = hub.Module(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM3F1a_RVsfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "df = json.loads(requests.get('https://raw.githubusercontent.com/clinc/oos-eval/master/data/data_oos_plus.json').text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naN4zCelW_hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "''' Getting Training data '''\n",
        "inscope_train = pd.DataFrame(df['train'],columns=['query','intent'])\n",
        "oss_train = pd.DataFrame(df['oos_train'],columns=['query','intent'])\n",
        "\n",
        "''' Getting Validation data '''\n",
        "inscope_val = pd.DataFrame(df['val'],columns=['query','intent'])\n",
        "oss_val = pd.DataFrame(df['oos_val'],columns=['query','intent'])\n",
        "\n",
        "''' Getting Test data '''\n",
        "inscope_test = pd.DataFrame(df['test'],columns=['query','intent'])\n",
        "oss_test = pd.DataFrame(df['oos_test'],columns=['query','intent'])\n",
        "\n",
        "\n",
        "train_df = pd.concat([inscope_train,oss_train])\n",
        "val_df = pd.concat([inscope_val,oss_val])\n",
        "test_df = pd.concat([inscope_test,oss_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIE-W2gKe7uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.append(val_df).reset_index(drop=True)\n",
        "x = train_df.append(test_df).reset_index(drop=True)\n",
        "\n",
        "X = x['query'].values\n",
        "Y = x['intent'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyD0bV93fpqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "41cc29c8-1a4b-4481-a2c3-ec662363536f"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(Y)\n",
        "le.classes_"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['accept_reservations', 'account_blocked', 'alarm',\n",
              "       'application_status', 'apr', 'are_you_a_bot', 'balance',\n",
              "       'bill_balance', 'bill_due', 'book_flight', 'book_hotel',\n",
              "       'calculator', 'calendar', 'calendar_update', 'calories', 'cancel',\n",
              "       'cancel_reservation', 'car_rental', 'card_declined', 'carry_on',\n",
              "       'change_accent', 'change_ai_name', 'change_language',\n",
              "       'change_speed', 'change_user_name', 'change_volume',\n",
              "       'confirm_reservation', 'cook_time', 'credit_limit',\n",
              "       'credit_limit_change', 'credit_score', 'current_location',\n",
              "       'damaged_card', 'date', 'definition', 'direct_deposit',\n",
              "       'directions', 'distance', 'do_you_have_pets', 'exchange_rate',\n",
              "       'expiration_date', 'find_phone', 'flight_status', 'flip_coin',\n",
              "       'food_last', 'freeze_account', 'fun_fact', 'gas', 'gas_type',\n",
              "       'goodbye', 'greeting', 'how_busy', 'how_old_are_you',\n",
              "       'improve_credit_score', 'income', 'ingredient_substitution',\n",
              "       'ingredients_list', 'insurance', 'insurance_change',\n",
              "       'interest_rate', 'international_fees', 'international_visa',\n",
              "       'jump_start', 'last_maintenance', 'lost_luggage', 'make_call',\n",
              "       'maybe', 'meal_suggestion', 'meaning_of_life',\n",
              "       'measurement_conversion', 'meeting_schedule', 'min_payment', 'mpg',\n",
              "       'new_card', 'next_holiday', 'next_song', 'no', 'nutrition_info',\n",
              "       'oil_change_how', 'oil_change_when', 'oos', 'order',\n",
              "       'order_checks', 'order_status', 'pay_bill', 'payday', 'pin_change',\n",
              "       'play_music', 'plug_type', 'pto_balance', 'pto_request',\n",
              "       'pto_request_status', 'pto_used', 'recipe', 'redeem_rewards',\n",
              "       'reminder', 'reminder_update', 'repeat',\n",
              "       'replacement_card_duration', 'report_fraud', 'report_lost_card',\n",
              "       'reset_settings', 'restaurant_reservation', 'restaurant_reviews',\n",
              "       'restaurant_suggestion', 'rewards_balance', 'roll_dice',\n",
              "       'rollover_401k', 'routing', 'schedule_maintenance',\n",
              "       'schedule_meeting', 'share_location', 'shopping_list',\n",
              "       'shopping_list_update', 'smart_home', 'spelling',\n",
              "       'spending_history', 'sync_device', 'taxes', 'tell_joke', 'text',\n",
              "       'thank_you', 'time', 'timer', 'timezone', 'tire_change',\n",
              "       'tire_pressure', 'todo_list', 'todo_list_update', 'traffic',\n",
              "       'transactions', 'transfer', 'translate', 'travel_alert',\n",
              "       'travel_notification', 'travel_suggestion', 'uber',\n",
              "       'update_playlist', 'user_name', 'vaccines', 'w2', 'weather',\n",
              "       'what_are_your_hobbies', 'what_can_i_ask_you', 'what_is_your_name',\n",
              "       'what_song', 'where_are_you_from', 'whisper_mode',\n",
              "       'who_do_you_work_for', 'who_made_you', 'yes'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vB4efTgtbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def decode(le, one_hot):\n",
        "    dec = np.argmax(one_hot, axis=1)\n",
        "    return le.inverse_transform(dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWXxQnC_hMN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = encode(le, ['order_checks', 'travel_suggestion', 'uber', 'what_is_your_name'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxZDiJ0ThbfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1db09b53-ea4c-4b98-9c52-a580dcf8fe5c"
      },
      "source": [
        "untest = decode(le, test)\n",
        "untest"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['order_checks', 'travel_suggestion', 'uber', 'what_is_your_name'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7Uf9wkW43xv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "963afbbf-c52e-4f7e-9418-121654555f91"
      },
      "source": [
        "x_enc = X\n",
        "y_enc = encode(le, Y)\n",
        "x_enc.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23850,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em71G_VKhgnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_enc, y_enc, test_size = 0.3, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPGpBmHNiRMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense\n",
        "from keras.models import Model\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phvcRZrklm4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BuRHbV8lpWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4323e648-7a29-428d-8566-dfb3dbbf1715"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 150\n",
        "input_text = Input(shape=(1,),dtype=tf.string)\n",
        "embedding = Lambda(UniversalEmbedding, output_shape=(512, ))(input_text)\n",
        "dense = Dense(256, activation='relu')(embedding)\n",
        "pred = Dense(151, activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6HnEUgals9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ecb43a4e-9ac0-4c20-fc11-d96c7cdc8235"
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(x_train, y_train, epochs=7, batch_size=32)\n",
        "    model.save_weights('./model.h5')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "16695/16695 [==============================] - 180s 11ms/step - loss: 2.0839 - accuracy: 0.5963\n",
            "Epoch 2/7\n",
            "16695/16695 [==============================] - 179s 11ms/step - loss: 0.4592 - accuracy: 0.9010\n",
            "Epoch 3/7\n",
            "16695/16695 [==============================] - 180s 11ms/step - loss: 0.3025 - accuracy: 0.9263\n",
            "Epoch 4/7\n",
            "16695/16695 [==============================] - 180s 11ms/step - loss: 0.2335 - accuracy: 0.9418\n",
            "Epoch 5/7\n",
            "16695/16695 [==============================] - 180s 11ms/step - loss: 0.1938 - accuracy: 0.9518\n",
            "Epoch 6/7\n",
            "16695/16695 [==============================] - 179s 11ms/step - loss: 0.1628 - accuracy: 0.9593\n",
            "Epoch 7/7\n",
            "16695/16695 [==============================] - 180s 11ms/step - loss: 0.1410 - accuracy: 0.9652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHoe0oCJnf3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model.load_weights('./model.h5')  \n",
        "    predicts = model.predict(x_test, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPyxP4DStf7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = decode(le, y_test)\n",
        "y_preds = decode(le, predicts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k39x53atLGSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "boolean_test = (y_test != 'oos')\n",
        "y_test_inclass = y_test[y_test != 'oos']\n",
        "y_test_pred_inclass = [y_preds[i] for i in range(len(y_preds)) if boolean_test[i]]\n",
        "\n",
        "print(\"Inscope_Accuracy using SVM (USE Embeddings)\",metrics.accuracy_score(y_true = y_test_inclass,y_pred = y_test_pred_inclass))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hry20Aa-LrRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "true_positives_test = Counter(np.logical_and(y_preds == 'oos',y_test == 'oos'))[True]\n",
        "false_negatives_test = Counter(np.logical_and(y_preds != 'oos',y_test == 'oos'))[True]\n",
        "\n",
        "test_recall = (true_positives_test)/(true_positives_test+false_negatives_test)\n",
        "\n",
        "print(\"Out_of_Scope_Recall\",test_recall)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AndxY0QpKd2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# _,INSCOPE_ACCURACY = model.evaluate()\n",
        "print(metrics.confusion_matrix(y_test, y_preds))\n",
        "\n",
        "print('Inscope-accuracy:',metrics.accuracy_score(y_test, y_preds))\n",
        "print(metrics.classification_report(y_test, y_preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V44W0lXFLpPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M3X2anBLqG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEbic-zRKhlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}